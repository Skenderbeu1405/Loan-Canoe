{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook is intended to provide a Python-based solution to importing our project CSV files into a PostgreSQL Database.  The two coding challenges we face are:**\n",
    "\n",
    "a) Getting the AWS RDS DB Connection to work.  \n",
    "The key thing I had to do with Amazon RDS was set Public Accessibility = Yes, and then edit inbound traffic under the Security Rules to whitelist the relevant IP address. This article hit on the basic points and then I figured out how to do this in AWS RDS/EC2.\n",
    "https://aws.amazon.com/getting-started/tutorials/create-connect-postgresql-db/\n",
    "\n",
    "b) Importing CSV data with missing values into PostgreSQL.\n",
    "The CSV Data Source for the project has missing values noted as empty strings which cannot be imported directly from CSV to PostgreSQL (due to a PostgreSQL Bug).  Also of note, the read CSV step has to occur row by row because our files are too large to hold a whole year of data in local memory.\n",
    "\n",
    "OPTION A (FAILED) \"COPY FROM\" does not work on null=\"\" because PostgreSQL doesn't handle it. Pulled relevant cell from the notebook for now but we may add it back in, to implement Option C below.\n",
    "\n",
    "OPTION B (FAILED) Pandas is not working, either, because it relies on \"IMPORT INTO\", which converts the null value back to an empty string to pass the SQL statement in Python bindings.  \n",
    "\n",
    "OPTION C (PENDING) Likely solution is to cast all fields as VARCHAR to start, then change type following initial import.  Will code this out at a later date.\n",
    "https://www.postgresql.org/message-id/4C882E8E.6080301%40postnewspapers.com.au\n",
    "https://github.com/cockroachdb/cockroach/issues/19743\n",
    "https://forum.cockroachlabs.com/t/import-from-csv-fails-on-null-data-for-int-types/1067/11\n",
    "https://stackoverflow.com/questions/13125236/sqlalchemy-psycopg2-and-postgresql-copy\n",
    "https://stackoverflow.com/questions/21527057/python-parse-csv-ignoring-comma-with-double-quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python objects for script\n",
    "\n",
    "hmda_schema = 'public'\n",
    "tables = ['17', '16', '15', '14', '13', '12']\n",
    "year = tables[2]\n",
    "test_table = f'hmda_lar_20{year}_allrecords'\n",
    "\n",
    "path = ''\n",
    "csv_file_path = f'{path}{test_table}.csv'\n",
    "\n",
    "print(csv_file_path)\n",
    "print(test_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres username, password, and database name.\n",
    "postgres_host = ''  \n",
    "postgres_port = '5432' \n",
    "postgres_username = '' \n",
    "postgres_password = ''\n",
    "postgres_dbname = ''\n",
    "postgres_str = ('postgresql://{username}:{password}@{host}:{port}/{dbname}'\n",
    "                .format(username = postgres_username,\n",
    "                        password = postgres_password,\n",
    "                        host = postgres_host,\n",
    "                        port = postgres_port,\n",
    "                        dbname = postgres_dbname)\n",
    "               )\n",
    "\n",
    "\n",
    "# Creating the connection.\n",
    "engine = create_engine(postgres_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(f'DROP TABLE IF EXISTS {test_table};')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quickest way to code table header is pulling from test file, then using df.to_sql**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_for_header_df = ''\n",
    "df = pd.read_csv(path_for_header_df, low_memory=False)\n",
    "df[:0].to_sql(test_table, engine, if_exists='fail', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a basic CSV iterator, since we can't read a whole year of data into local memory.  This cell works.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    with open(csv_file_path, 'rt') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            yield row\n",
    "\n",
    "g = read_csv(csv_file_path)\n",
    "next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This next cell does not work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    # First open the file\n",
    "    with open(path, 'rt') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader, None)\n",
    "        #have to preprocess our data so that PostgreSQL can handle it\n",
    "        for row in reader:   \n",
    "            df = pd.DataFrame(columns = ['tract_to_msamd_income', 'rate_spread', 'population', 'minority_population', 'number_of_owner_occupied_units', 'number_of_1_to_4_family_units', 'loan_amount_000s', 'hud_median_family_income', 'applicant_income_000s', 'state_name', 'state_abbr', 'sequence_number', 'respondent_id', 'purchaser_type_name', 'property_type_name', 'preapproval_name', 'owner_occupancy_name', 'msamd_name', 'loan_type_name', 'loan_purpose_name', 'lien_status_name', 'hoepa_status_name', 'edit_status_name', 'denial_reason_name_3', 'denial_reason_name_2', 'denial_reason_name_1', 'county_name', 'co_applicant_sex_name', 'co_applicant_race_name_5', 'co_applicant_race_name_4', 'co_applicant_race_name_3', 'co_applicant_race_name_2', 'co_applicant_race_name_1', 'co_applicant_ethnicity_name', 'census_tract_number', 'as_of_year', 'application_date_indicator', 'applicant_sex_name', 'applicant_race_name_5', 'applicant_race_name_4', 'applicant_race_name_3', 'applicant_race_name_2', 'applicant_race_name_1', 'applicant_ethnicity_name', 'agency_name', 'agency_abbr', 'action_taken_name'])\n",
    "            df.loc[0] = row\n",
    "            print(df)\n",
    "            df.to_sql(test_table, engine, schema=None, if_exists='append', \n",
    "                             index=False, index_label=None, chunksize=None, dtype=None, method=None)\n",
    "            \n",
    "    conn.commit()\n",
    "    \n",
    "read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once we find a coding approach that works, the below cells verify whether the table now exists.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tables= '''SELECT\n",
    "   *\n",
    "FROM\n",
    "   pg_catalog.pg_tables\n",
    "WHERE\n",
    "   schemaname != 'pg_catalog'\n",
    "AND schemaname != 'information_schema';'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Current tables:')\n",
    "current_tables = pd.read_sql_query(show_tables,engine)\n",
    "print(current_tables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
